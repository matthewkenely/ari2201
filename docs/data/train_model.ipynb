{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.gold import biluo_tags_from_offsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./location_articles_images.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:639: UserWarning: [W033] Training a new parser or NER using a model with an empty lexeme normalization table. This may degrade the performance to some degree. If this is intentional or this language doesn't have a normalization table, please ignore this warning.\n",
      "  **kwargs\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:639: UserWarning: [W034] Please install the package spacy-lookups-data in order to include the default lexeme normalization table for the language 'en'.\n",
      "  **kwargs\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"AttivitÃ  Politika TaÄ§t it-Tinda fil-MostaMiegÄ§ek G...\" with entities \"[(36, 41, 'LOC')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"A planning application to transform San Gwann â€™ s ...\" with entities \"[(1724, 1732, 'LOC'), (4597, 4605, 'LOC'), (7932, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"ðŸ”µ LIVE Iltaqa â€™ mal-kandidati tal-1 Distrett fil-Ä¦...\" with entities \"[(49, 55, 'LOC'), (2568, 2576, 'LOC'), (2577, 2585...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"MiegÄ§ek f'BirÅ¼ebbuÄ¡aMiegÄ§ek GÄ§al Malta ðŸ‡²ðŸ‡¹ PN leade...\" with entities \"[(10, 20, 'LOC')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"2022 was wrapped up with eight homicides as a stat...\" with entities \"[(929, 935, 'LOC'), (3463, 3468, 'LOC'), (3845, 38...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"The Malta Police Union has decried the â€œ sub-stand...\" with entities \"[(1755, 1763, 'LOC'), (1784, 1790, 'LOC'), (1791, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Video â€“ The Archdiocese of Malta In the hours prec...\" with entities \"[(528, 536, 'LOC'), (793, 801, 'LOC'), (874, 879, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Il-Kap tal-Partit Nazzjonalista Bernard Grech inte...\" with entities \"[(74, 84, 'LOC')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"A bill that will introduce harsher penalties for t...\" with entities \"[(3206, 3212, 'LOC'), (3364, 3370, 'LOC'), (3751, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Notaries have been warned by their regulating body...\" with entities \"[(924, 930, 'LOC'), (1504, 1510, 'LOC'), (1656, 16...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Many know Kenneth Vella as an expert journalist on...\" with entities \"[(139, 144, 'LOC'), (283, 288, 'LOC'), (3050, 3055...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"A Facebook page which deals with roads in Malta ha...\" with entities \"[(293, 299, 'LOC'), (779, 783, 'LOC'), (788, 793, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"If the Labour Party is elected into power on 26 Ma...\" with entities \"[(156, 166, 'LOC'), (645, 655, 'LOC'), (1470, 1480...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Videos of the routes through which Pope Francis wi...\" with entities \"[(377, 385, 'LOC'), (386, 394, 'LOC'), (420, 428, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Mass Rally fi Pjazza San Ä orÄ¡ indirizzat mill-Kap ...\" with entities \"[(293, 301, 'LOC'), (2456, 2464, 'LOC'), (2566, 25...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ambjent Malta spent over â‚¬117 million from financi...\" with entities \"[(227, 232, 'LOC'), (618, 623, 'LOC')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"A dead horse has remained uncollected in a field i...\" with entities \"[(52, 57, 'LOC'), (734, 739, 'LOC'), (3012, 3020, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\Matthew Kenely\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"The Department of Fisheries and Aquaculture is inv...\" with entities \"[(1082, 1092, 'LOC'), (1093, 1103, 'LOC'), (1158, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Loss: {'ner': 4284.699882544678}\n",
      "Iteration: 2 Loss: {'ner': 582.0260120187124}\n",
      "Iteration: 3 Loss: {'ner': 471.4962829265851}\n",
      "Iteration: 4 Loss: {'ner': 490.13240249558123}\n",
      "Iteration: 5 Loss: {'ner': 444.8642770157581}\n",
      "Iteration: 6 Loss: {'ner': 414.7206825535903}\n",
      "Iteration: 7 Loss: {'ner': 364.3854902133923}\n",
      "Iteration: 8 Loss: {'ner': 340.8676235179898}\n",
      "Iteration: 9 Loss: {'ner': 382.2143335794164}\n",
      "Iteration: 10 Loss: {'ner': 282.90911721515255}\n"
     ]
    }
   ],
   "source": [
    "# Load the base English model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create and add the NER pipeline\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner, last=True)\n",
    "\n",
    "# Define your labels (e.g., \"LOCATION\")\n",
    "labels = ['LOC']\n",
    "\n",
    "# Load and preprocess your training data\n",
    "train_data = []\n",
    "for body, entities in zip(df['body'], df['entities']):\n",
    "    entities = eval(entities)\n",
    "    train_data.append((body, {\"entities\": entities}))\n",
    "\n",
    "# train_data = train_data[:500]\n",
    "\n",
    "# Initialize the NER model with the labels\n",
    "for label in labels:\n",
    "    ner.add_label(label)\n",
    "\n",
    "# Train the NER model\n",
    "optimizer = nlp.begin_training()\n",
    "for itn in range(10):  # Adjust the number of iterations as needed\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "    for text, annotations in train_data:\n",
    "        nlp.update([text], [annotations], drop=0.3, losses=losses)\n",
    "    print(\"Iteration:\", itn+1, \"Loss:\", losses)\n",
    "\n",
    "# Save the trained model\n",
    "nlp.to_disk(\"trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'model_2.0'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42328\\3165898609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the trained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model_2.0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Test the trained model on new article text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"I'd like to go to Valletta and eat there.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'model_2.0'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "nlp = spacy.load(\"model_2.0\")\n",
    "\n",
    "# Test the trained model on new article text\n",
    "text = \"I'd like to go to Valletta and eat there.\"\n",
    "doc = nlp(text)\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "# predict location of text\n",
    "\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In preparation for the solemnity of Pentecost when we celebrate the descent of the Holy Spirit and the birth of the church the traditional devotion of the Easter season the Via Lucis or Way of Light will be prayed at St Joseph the Worker Parish Church Birkirkara on Saturday May 20 at 8pm Everyone is invited to join in the contemplation of these 14 Stations of Light Each gospel passage will be proclaimed in 14 different languages to remind that while different we are all one in the power of the Holy Spirit More information on evangelisationmaltadioceseorg'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(252, 262, 'LOC')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(test.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'U-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp.make_doc(test.body)\n",
    "tags = biluo_tags_from_offsets(doc, eval(test.entities))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'â€˜No one believes youâ€™ on hospitals fiasco Grech tells Labour MPs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "''.join([i for i in 'â€˜No one believes youâ€™ on hospitals fiasco, Grech tells Labour MPs' if i not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p += ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drug', 'kill']\n"
     ]
    }
   ],
   "source": [
    "with open('filter.txt', 'r') as f:\n",
    "    x = f.readlines()\n",
    "    print([i.strip() for i in x])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
